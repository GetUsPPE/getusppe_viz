{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import us\n",
    "import plotly.graph_objects as go\n",
    "from plotly.offline import plot\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Was having issues loading the direct link, so for now I load from desktop.\n",
    "# Note that the csv file is not on Github.\n",
    "survey = pd.read_csv(\"request_details.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure zip codes have leading zeros.\n",
    "survey['Zip'] = survey['Zip'].apply(lambda x: '{0:0>5}'.format(x))\n",
    "# Only use the first five digits so it's a valid zipcode\n",
    "survey['Zip'] = survey['Zip'].astype(str).str[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some string fields have formatting issues.\n",
    "columns = survey.select_dtypes(include='object').columns\n",
    "for column in columns:\n",
    "    survey[column] = survey[column].str.replace('\\xa0', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppes = ['N95', 'Surgical Mask', 'Face Shield', 'Booties', 'Gloves', 'Gown', \n",
    "        'Sanitizer', 'Wipes', 'Thermometer', 'Homemade Mask', 'Other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ppe in ppes:\n",
    "    percent_filled_out = 100 * (1 - np.mean(pd.isnull(survey['Requesting {}'.format(ppe)])))\n",
    "    print(\"{:.1f}% left an answer for whether they need {}.\".format(percent_filled_out, ppe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For now, drop 'Surgical Mask' because there was a bug in the survey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppes = ['N95', 'Face Shield', 'Booties', 'Gloves', 'Gown', \n",
    "        'Sanitizer', 'Wipes', 'Thermometer', 'Homemade Mask', 'Other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all rows which have null values for any of the PPEs/\n",
    "valid_requests = survey\n",
    "for ppe in ppes:\n",
    "    valid_requests = valid_requests[valid_requests['Requesting {}'.format(ppe)].notnull()]\n",
    "    valid_requests['Requesting {}'.format(ppe)] = valid_requests[\n",
    "        'Requesting {}'.format(ppe)].replace({'Yes': True, 'No': False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Still keeping 81% of DF, probably about the best we could do.\n",
    "len(valid_requests) / len(survey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ppe in ppes:\n",
    "    percent_needing_ppe = 100 * np.mean(valid_requests['Requesting {}'.format(ppe)].astype(int))\n",
    "    print(\"{:.1f}% of respondents need {}.\".format(percent_needing_ppe, ppe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot pie chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(5, 2, figsize=(10, 15))\n",
    "fig.tight_layout(pad=3.0)\n",
    "order = [3, 2, 0, 1, 4]\n",
    "count = 0\n",
    "colors = [\"#FDFCEF\",\"#FFDA55\",\"#FFC831\",\"#FC7555\",\"#E96E81\"]\n",
    "for ppe in ppes:\n",
    "    ppe_stock = np.array(valid_requests[~pd.isnull(valid_requests['{} Stock'.format(ppe)])]['{} Stock'.format(ppe)])\n",
    "    ppe_unique, ppe_counts = np.unique(ppe_stock, return_counts=True)\n",
    "    labels = ppe_unique[order]\n",
    "    percentages = (ppe_counts / np.sum(ppe_counts) * 100)[order]\n",
    "    axs[count // 2, count % 2].pie(percentages, labels=labels, colors=colors, autopct='%1.0f%%')\n",
    "    axs[count // 2, count % 2].set_title(\"{} Supply Remaining (n={})\".format(ppe, len(ppe_stock)), size=16)\n",
    "    count += 1\n",
    "plt.savefig(\"supplies_remaining.png\", dpi=200, bbox_to_anchor='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Supply by region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slightly modify Matt's plotting functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.offline import plot\n",
    "\n",
    "def choropleth_mapbox_usa_plot(counties, locations, z, text,\n",
    "                                colorscale = \"RdBu_r\", zmin=-1, zmax=10, \n",
    "                                title='choropleth_mapbox_usa_plot',\n",
    "                                colorbar_title = 'count',\n",
    "                                html_filename='plot.html',\n",
    "                                show_fig=True):\n",
    "    \n",
    "    # Choropleth graph. For reference: https://plotly.com/python/mapbox-county-choropleth/\n",
    "    fig = go.Figure(go.Choroplethmapbox(\n",
    "        geojson=counties, locations=locations, z=z, text=text,\n",
    "        colorscale=colorscale,zmin=zmin,zmax=zmax,marker_opacity=0.8, \n",
    "        marker_line_width=0.5, colorbar_title=colorbar_title, hoverinfo='text'\n",
    "        ))\n",
    "    \n",
    "    # Center on US\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        mapbox_style=\"carto-positron\",\n",
    "        mapbox_zoom=3.5, \n",
    "        mapbox_center = {\"lat\": 37.0902, \"lon\": -95.7129},\n",
    "        margin={\"r\":100,\"t\":30,\"l\":30,\"b\":0},\n",
    "    )\n",
    "\n",
    "    # Show the figure\n",
    "    if show_fig:\n",
    "        fig.show()\n",
    "    \n",
    "    # Download the figure From Sunny Mui\n",
    "    go.Figure.write_html(fig, file=html_filename, config={'responsive': True}, include_plotlyjs='cdn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_county_geojson_and_merge_df(geojson_url, mask_df_counties, number_to_category, county_label=\"Stock\"):\n",
    "    \"\"\"mask_df_counties just needs to have fields for 'fips' and 'counts'.\"\"\"\n",
    "    # Download the data\n",
    "    s=requests.get(geojson_url).text\n",
    "\n",
    "    # Extract the json format, and find column headers\n",
    "    counties = json.loads(s)\n",
    "    \n",
    "    # Create counties_df from geojson counties object\n",
    "    counties_df = pd.DataFrame.from_dict(counties['features'])\n",
    "    counties_df['properties'][0]\n",
    "\n",
    "    # extract properties dict, then concatenate new clumsn and remove old properties column\n",
    "    counties_df = pd.concat(\n",
    "        [counties_df, pd.json_normalize(counties_df['properties'])], axis=1).drop(['properties'], axis=1)\n",
    "\n",
    "    # clean up the dataframe                                                                               \n",
    "    counties_df.drop(['type','COUNTY','LSAD'], axis=1, inplace=True)\n",
    "    counties_df.rename(columns={'id':'fips','NAME':'county'}, inplace=True)\n",
    "    counties_df.head()\n",
    "    \n",
    "        \n",
    "    # join with the dataframe that has ppe requests: mask_df\n",
    "    merged_df = counties_df.join(\n",
    "        mask_df_counties[['fips','counts']].set_index('fips'),\n",
    "        on='fips',  how='left', lsuffix='counties', rsuffix='mask_df')\n",
    "\n",
    "    # fill the NA in counts with 0s\n",
    "    merged_df['counts'].fillna(0, inplace=True)\n",
    "    \n",
    "    # change name of column 'counts' to 'PPE_requests' \n",
    "    merged_df.rename(inplace=True,\n",
    "        columns={'counts':'PPE_requests'})\n",
    "    \n",
    "    # Map fips state code to state name\n",
    "    merged_df['STATE'] = merged_df.apply(\n",
    "        lambda x: us.states.lookup(x['STATE']), axis=1)\n",
    "    merged_df['county_info_for_map'] = merged_df.apply(\n",
    "        lambda x: ('PPE Requests: %s, %s'%(x['county'],x['STATE'])), axis=1)\n",
    "    \n",
    "    # Create text column for use in mapping\n",
    "    merged_df['ppe_text'] = '{}: '.format(county_label) + merged_df.apply(lambda x: number_to_category[x['PPE_requests']], axis=1) + '<br>'+ \\\n",
    "        merged_df['county'].astype(str) + ', ' + merged_df['STATE'].astype(str)\n",
    "    \n",
    "    # return a json object called counties for plotting, and a counties_df for joins+manipulation of other data\n",
    "    return counties, merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge zips and FIPS.\n",
    "zip_county_crosswalk = pd.read_csv(\n",
    "    'zip_county_crosswalk.csv', converters={'ZIP': lambda x: str(x), \n",
    "                                            'COUNTY': lambda x: str(x)})\n",
    "zip_county_crosswalk.columns = map(str.lower, zip_county_crosswalk.columns)\n",
    "\n",
    "# Some zipcodes have multiple FIPS codes, so use the FIPS code that has the largest overlap.\n",
    "idx = (zip_county_crosswalk.groupby(['zip'])['tot_ratio'].transform(max) == \n",
    "       zip_county_crosswalk['tot_ratio'])\n",
    "zip_max_county = zip_county_crosswalk[idx]\n",
    "zip_max_county['fips'] = zip_max_county['county']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "requests_with_fips = pd.merge(valid_requests, \n",
    "                              zip_max_county[['zip', 'fips']], \n",
    "                              left_on='Zip', \n",
    "                              right_on='zip').drop('zip', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lost 5 rows but whatever\n",
    "len(requests_with_fips) / len(valid_requests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of requests by county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_to_category = {'No supply remaining': 5, '2 days or less': 4, '1 week or less': 3, \n",
    "                 '2 weeks or less': 2, 'More than 2 weeks': 1}\n",
    "number_to_category = {5: 'No supply remaining', 4: '2 days or less', 3: '1 week or less', \n",
    "                  2: '2 weeks or less', 1: 'More than 2 weeks', 0: 'No data'}\n",
    "geojson_url = 'https://raw.githubusercontent.com/plotly/datasets/master/geojson-counties-fips.json'\n",
    "for ppe in ppes:\n",
    "    ppe_requests = requests_with_fips[['fips', '{} Stock'.format(ppe)]]\n",
    "    ppe_requests = ppe_requests[~pd.isnull(ppe_requests['{} Stock'.format(ppe)])]\n",
    "    ppe_requests['counts'] = ppe_requests.apply(lambda x: stock_to_category[x['{} Stock'.format(ppe)]], axis=1)\n",
    "    # Aggregate by mode\n",
    "    ppe_average_stock = ppe_requests[['fips', 'counts']].groupby('fips').agg(lambda x:x.value_counts().index[0]).reset_index()\n",
    "    counties, merged_df = download_county_geojson_and_merge_df(geojson_url, ppe_average_stock, number_to_category)\n",
    "    # Couldn't figure out how to fix the labels on the colorbar, but at least the hover has the right categories.\n",
    "    choropleth_mapbox_usa_plot(\n",
    "        counties = counties,\n",
    "        locations = merged_df.fips,\n",
    "        z = merged_df.PPE_requests,\n",
    "        text = merged_df.ppe_text,\n",
    "        colorscale = [\"#fdfcef\",\"#c7e9b4\",\"#D2FBFF\",\"#36A2B9\",\"#004469\"],\n",
    "        zmin = 0,\n",
    "        zmax=5,\n",
    "        title = '{} Stock by County (Hover for breakdown)'.format(ppe),\n",
    "        colorbar_title = '{} Stock (Darker is less)'.format(ppe),\n",
    "        html_filename = 'stock_maps/{}_Stock_By_County.html'.format(ppe.replace(' ', '_')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping total requests by region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick all rows that have a non-null value for N95, since it is most frequently requested.\n",
    "ppe_request_counts = requests_with_fips.groupby('fips').aggregate('count').reset_index()[['fips', 'Requesting N95']]\n",
    "ppe_request_counts['counts'] = ppe_request_counts['Requesting N95']\n",
    "number_to_category={}\n",
    "for i in range(50):\n",
    "    number_to_category[i] = str(i)\n",
    "counties, merged_df = download_county_geojson_and_merge_df(geojson_url, ppe_request_counts, number_to_category, \n",
    "                                                          county_label='Requests')\n",
    "choropleth_mapbox_usa_plot(\n",
    "        counties = counties,\n",
    "        locations = merged_df.fips,\n",
    "        z = merged_df.PPE_requests,\n",
    "        text = merged_df.ppe_text,\n",
    "        colorscale = [\"#fdfcef\",\"#c7e9b4\",\"#D2FBFF\",\"#36A2B9\",\"#004469\"],\n",
    "        zmin = 0,\n",
    "        zmax=5,\n",
    "        title = 'Requests by County (Hover for breakdown)',\n",
    "        colorbar_title = 'Requests',\n",
    "        html_filename = 'stock_maps/Requests_By_County.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By type of institution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "institution_types =  np.array(['Acute Care Hospital', 'Non-Acute Care Hospital',\n",
    "       'Freestanding Emergency Room', 'Urgent Care Clinic', 'Field Hospital',\n",
    "       'Hospital Overflow Facility', 'EMS of Fire Department',\n",
    "       'Independent Clinic', 'Federally Qualified Health Center (FQHC)',\n",
    "       'Disproportionate Share Hospital', 'Critical Access',\n",
    "       'Rural Health Clinic', 'Public Health Clinic',\n",
    "       'Tribal healthcare / Indian Health Service', 'Nursing Facility',\n",
    "       'Inpatent Rehabilitation Center',\n",
    "       'Residential Substance Treatment Center',\n",
    "       'Resident or Inpatient Psychiatric Facility', 'Police Department',\n",
    "       'Group Home', 'Assisted Living Facility',\n",
    "       'Correctional Facility/Detention Center', 'Homeless Shelter', 'Hospice',\n",
    "       'Home Health Aides/Other Home Services'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_list = []\n",
    "for institution_type in institution_types:\n",
    "    num_responses = np.sum(~valid_requests[institution_type].isna())\n",
    "    response_list.append(num_responses)\n",
    "response_list = np.array(response_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "institution_types = institution_types[np.argsort(-response_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for institution_type in institution_types:\n",
    "    num_responses = np.sum(~valid_requests[institution_type].isna())\n",
    "    print(\"{} responses from {}\".format(num_responses, institution_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pie chart of: for each PPE, what is the breakdown of facility types that have run out?\n",
    "sns.set()\n",
    "fig, axs = plt.subplots(5, 2, figsize=(20, 18))\n",
    "fig.tight_layout(pad=1.0)\n",
    "count = 0\n",
    "colors = [\"#FDFCEF\",\"#FFDA55\",\"#FFC831\",\"#FC7555\",\"#E96E81\"]\n",
    "for ppe in ppes:\n",
    "    type_to_num_ran_out = {}\n",
    "    # Look at 7 most popular institution types.\n",
    "    for institution_type in institution_types[:7]:\n",
    "        type_to_num_ran_out[institution_type] = np.sum(\n",
    "            valid_requests[~pd.isnull(valid_requests[institution_type])]['{} Stock'.format(ppe)] == \"No supply remaining\")\n",
    "    num_ran_out = np.array(list(type_to_num_ran_out.values()))\n",
    "    percentages = num_ran_out / np.sum(num_ran_out)\n",
    "    labels = list(type_to_num_ran_out.keys())\n",
    "    axs[count // 2, count % 2 * 1].pie(percentages, labels=labels, autopct='%1.0f%%')\n",
    "    axs[count // 2, count % 2 * 1].set_title(\"Institutions without {} (n={})\".format(\n",
    "            ppe, np.sum(num_ran_out)), size=16)\n",
    "    count += 1\n",
    "plt.subplots_adjust(top = 0.95)\n",
    "plt.savefig(\"institutions_without_ppe.png\", dpi=200, bbox_to_anchor='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
