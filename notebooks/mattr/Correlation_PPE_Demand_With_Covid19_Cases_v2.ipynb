{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation of PPE Demand in USA With Covid19 Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "from io import StringIO\n",
    "import os\n",
    "\n",
    "# computing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Import geopandas package\n",
    "import geopandas as gpd\n",
    "import reverse_geocoder as rg\n",
    "import addfips\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io\n",
    "from plotly.offline import plot\n",
    "import us\n",
    "\n",
    "# plotting\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "findthemasks_url = 'http://findthemasks.com/data.json'\n",
    "request_headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.3\"}\n",
    "county_fips_download_url = 'https://github.com/ShyamW/Geocoding_Suite/blob/master/Lat_Lng_to_County_Data/county_Fips.txt'\n",
    "geojson_url = 'https://raw.githubusercontent.com/plotly/datasets/master/geojson-counties-fips.json'\n",
    "ny_times_covid_date = '2020-03-30'\n",
    "ny_times_county_data_url = 'https://github.com/nytimes/covid-19-data/raw/master/us-counties.csv'\n",
    "# Import hospital information compiled by https://beta.covidmap.link/\n",
    "hospital_download_url = 'https://docs.google.com/spreadsheet/ccc?key=15gZsozGQp-wdJaSngvLV13iCf_2mm2IsZpHOPxZtvtI&output=csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download find the mask data and convert to pandas\n",
    "- Taken from find the mask [web visualization](https://findthemasks.com/give.html) \n",
    "- [Data updated every 5 mins here](findthemasks.com/data.json) - The data visulized here is from 3/25 at 10PM PST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_findthemasks_data(url,request_headers):\n",
    "    # Download the data\n",
    "    s=requests.get(url, headers= request_headers).text\n",
    "\n",
    "    # Extract the json format, and find column headers\n",
    "    json_data = json.loads(s)\n",
    "    HEADERS = json_data['values'][0]\n",
    "\n",
    "    # create the data frame\n",
    "    mask_df = pd.DataFrame.from_dict(json_data['values'][2:])\n",
    "    mask_df.columns=HEADERS\n",
    "    \n",
    "    # Using DataFrame.drop\n",
    "    mask_df = mask_df.dropna(how='any', subset=['Lat', 'Lng'])\n",
    "\n",
    "    # Rename the State? column\n",
    "    mask_df.rename(columns={'State?': 'State'}, inplace=True)\n",
    "\n",
    "    # Drop institutions with multiple entries\n",
    "    mask_df.drop_duplicates(subset='What is the name of the hospital or clinic?', inplace=True)\n",
    "\n",
    "    return mask_df\n",
    "\n",
    "\n",
    "mask_df = download_findthemasks_data(url = findthemasks_url, request_headers = request_headers)\n",
    "mask_df.head(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create geocoder class to find fips and county information by lat/long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class geocoder:\n",
    "    def __init__(self, county_fips_download_url):\n",
    "        self.af = addfips.AddFIPS()\n",
    "        self.download_county_fips_info(county_fips_download_url)\n",
    "        \n",
    "    def download_county_fips_info(self, url):\n",
    "        contents=requests.get(url).text\n",
    "        with open('county_Fips.txt', 'w') as f:\n",
    "            f.write(contents)    \n",
    "        \n",
    "    def fips_code_lookup(self, county, state):\n",
    "        # Lookup of fips code (https://github.com/fitnr/addfips)\n",
    "        fips = self.af.get_county_fips(county, state)\n",
    "        return fips\n",
    "\n",
    "    def get_geocoder_info_from_rg(self, Lat, Lng):\n",
    "        try:\n",
    "            # Reverse geocoder api call to get county name\n",
    "            coordinates = (Lat, Lng)\n",
    "            results = rg.search(coordinates) # default mode = 2\n",
    "            county = results[0]['admin2']\n",
    "            state = results[0]['admin1']\n",
    "\n",
    "            # Lookup of fips code (https://github.com/fitnr/addfips)\n",
    "            fips = self.fips_code_lookup(county,state)\n",
    "\n",
    "            # return the fip and county\n",
    "            return {'fips':fips, 'county':county}\n",
    "        except ValueError:\n",
    "            return {'fips':'NA', 'county':'NA'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search and add the FIPS code to each row - WILL TAKE SEVERAL MINS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_fips_county_info(mask_df, geocoder):\n",
    "    # Start tdqm timer from tqdm.auto\n",
    "    tqdm.pandas()\n",
    "\n",
    "    # Reverse geocoder used to get geocoded fips and county information\n",
    "    # Note: Progress_apply is used for the timer functionality\n",
    "    mask_df['geocoder'] = mask_df.progress_apply(\n",
    "        lambda x: geocoder.get_geocoder_info_from_rg(x['Lat'], x['Lng']), axis=1)\n",
    "\n",
    "    # Map the geocoder dict column to individual columns\n",
    "    mask_df['fips'] = mask_df.apply(\n",
    "        lambda x: x['geocoder']['fips'], axis=1)\n",
    "    mask_df['county'] = mask_df.apply(\n",
    "        lambda x: x['geocoder']['county'], axis=1)\n",
    "    mask_df.drop(columns=['geocoder'],inplace = True)\n",
    "\n",
    "    # Using DataFrame.drop to remove any fips code that could not be mapped\n",
    "    mask_df = mask_df.dropna(how='any', subset=['fips','county'])\n",
    "    \n",
    "    return mask_df\n",
    "\n",
    "geocoder = geocoder(county_fips_download_url)\n",
    "mask_df = add_fips_county_info(mask_df, geocoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sum amount of requests per county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def requests_per_county(mask_df, write_out_csv = True):\n",
    "    # Count the amount of requests per county\n",
    "    mask_df_counties=mask_df.groupby(['fips','county','State']).size().reset_index(name='counts')\n",
    "    \n",
    "    # write out this data file to csv\n",
    "    if write_out_csv:\n",
    "        timestr = time.strftime(\"%Y%m%d\")\n",
    "        path = 'findthemasks_data_processed_' + timestr + '.csv'\n",
    "        mask_df.to_csv (path, index = False, header=True)\n",
    "\n",
    "        ##### TODO\n",
    "        # Some of the data written out is corrupted and misaligned by row\n",
    "        # Not sure what the bug is right now\n",
    "    \n",
    "    return mask_df_counties\n",
    "\n",
    "\n",
    "mask_df_counties = requests_per_county(mask_df, write_out_csv = True)\n",
    "mask_df_counties.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download county geo information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_county_geojson(geojson_url):\n",
    "    # Download the data\n",
    "    s=requests.get(geojson_url).text\n",
    "\n",
    "    # Extract the json format, and find column headers\n",
    "    counties = json.loads(s)\n",
    "    \n",
    "    # Create counties_df from geojson counties object\n",
    "    counties_df = pd.DataFrame.from_dict(counties['features'])\n",
    "    counties_df['properties'][0]\n",
    "\n",
    "    # extract properties dict, then concatenate new clumsn and remove old properties column\n",
    "    counties_df = pd.concat(\n",
    "        [counties_df, pd.json_normalize(counties_df['properties'])], axis=1).drop(['properties'], axis=1)\n",
    "\n",
    "    # clean up the dataframe                                                                               \n",
    "    counties_df.drop(['type','COUNTY','LSAD'], axis=1, inplace=True)\n",
    "    counties_df.rename(columns={'id':'fips','NAME':'county'}, inplace=True)\n",
    "    counties_df.head()\n",
    "    \n",
    "    # join with the dataframe that has ppe requests: mask_df\n",
    "    merged_df = counties_df.join(\n",
    "        mask_df_counties[['fips','counts']].set_index('fips'),\n",
    "        on='fips',  how='left', lsuffix='counties', rsuffix='mask_df')\n",
    "\n",
    "    # fill the NA in counts with 0s\n",
    "    merged_df['counts'].fillna(0, inplace=True)\n",
    "    \n",
    "    # change name of column 'counts' to 'PPE_requests' \n",
    "    merged_df.rename(inplace=True,\n",
    "        columns={'counts':'PPE_requests'})\n",
    "    \n",
    "    # Map fips state code to state name\n",
    "    merged_df['STATE'] = merged_df.progress_apply(\n",
    "        lambda x: us.states.lookup(x['STATE']), axis=1)\n",
    "    merged_df['county_info_for_map'] = merged_df.progress_apply(\n",
    "        lambda x: ('PPE Requests: %s, %s'%(x['county'],x['STATE'])), axis=1)\n",
    "    \n",
    "    # Create text column for use in mapping\n",
    "    merged_df['ppe_text'] = 'PPE Requests: ' + merged_df['PPE_requests'].astype(int).astype(str) + '<br>'+ \\\n",
    "        merged_df['county'].astype(str) + ', ' + merged_df['STATE'].astype(str)\n",
    "\n",
    "\n",
    "    \n",
    "    # return a json object called counties for plotting, and a counties_df for joins+manipulation of other data\n",
    "    return counties, merged_df\n",
    "\n",
    "\n",
    "counties, merged_df = download_county_geojson(geojson_url)\n",
    "merged_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for mapping requests by County"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def choropleth_mapbox_usa_plot (counties, locations, z, text,\n",
    "                                colorscale = \"RdBu_r\", zmin=-1, zmax=10, \n",
    "                                title='choropleth_mapbox_usa_plot',\n",
    "                                colorbar_title = 'count',\n",
    "                                html_filename='plot.html'):\n",
    "    \n",
    "    # Choropleth graph. For reference: https://plotly.com/python/mapbox-county-choropleth/\n",
    "    fig = go.Figure(go.Choroplethmapbox(\n",
    "        geojson=counties, locations=locations, z=z, text=text,\n",
    "        colorscale=colorscale,zmin=zmin,zmax=zmax,marker_opacity=0.8, \n",
    "        marker_line_width=0.5, colorbar_title=colorbar_title, hoverinfo='text'\n",
    "        ))\n",
    "    \n",
    "    # Center on US\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        mapbox_style=\"carto-positron\",\n",
    "        mapbox_zoom=3.5, \n",
    "        mapbox_center = {\"lat\": 37.0902, \"lon\": -95.7129},\n",
    "        margin={\"r\":300,\"t\":30,\"l\":30,\"b\":0},\n",
    "    )\n",
    "    # Download the figure\n",
    "    plot(fig, filename=html_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map of PPE Requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choropleth_mapbox_usa_plot(\n",
    "    counties = counties,\n",
    "    locations = merged_df.fips,\n",
    "    z = merged_df.PPE_requests,\n",
    "    text = merged_df.ppe_text,\n",
    "    #colorscale = [\"#fdfcef\", \"#c7e9b4\", \"#6ab7a6\",\"#41b6c4\",\"#2c7fb8\",\"#253494\"],\n",
    "    colorscale = [\"#fdfcef\",\"#c7e9b4\",\"#D2FBFF\",\"#36A2B9\",\"#004469\"],\n",
    "    zmin = 0,\n",
    "    zmax=5,\n",
    "    title = ('PPE Requests By County - %s - (Hover for breakdown)' % time.strftime(\"%Y%m%d\")),\n",
    "    colorbar_title = '> PPE Requests',\n",
    "    html_filename = 'PPE_Requests_By_County.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download COVID19 data and convert to pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def download_findthemasks_data(url, date, write_out_csv = True):\n",
    "    covid_df = pd.read_csv(url)\n",
    "    covid_df = covid_df.loc[covid_df['date'] == date]\n",
    "\n",
    "    # NYC data is missing county, so make them all New York County.\n",
    "    covid_df.loc[covid_df['county'] == 'New York City', 'fips'] = '36061'\n",
    "    # Kansas City data is missing the specific county so make them all Cook County\n",
    "    covid_df.loc[(covid_df['county'] == 'Kansas City') & \n",
    "              (covid_df['state'] == 'Missouri'), 'fips'] = '29095'\n",
    "    \n",
    "    # drop the rows without a fips value\n",
    "    covid_df = covid_df.dropna(how='any', subset=['fips'])\n",
    "\n",
    "    # convert to int to remove the decimal values\n",
    "    covid_df['fips'] = covid_df['fips'].apply(int)\n",
    "    \n",
    "    # Zfill all countyFIPS to be 5 characters\n",
    "    width=5\n",
    "    covid_df[\"fips\"]= covid_df[\"fips\"].astype(str)\n",
    "    covid_df[\"fips\"]= covid_df[\"fips\"].str.zfill(width) \n",
    "        \n",
    "    # write out this data file to csv\n",
    "    if write_out_csv:\n",
    "        timestr = time.strftime(\"%Y%m%d\")\n",
    "        path = 'COVID19_nytimes_' + date + ' data_processed_on_' + timestr + '.csv'\n",
    "        covid_df.to_csv (path, index = False, header=True)\n",
    "\n",
    "    return covid_df\n",
    "    \n",
    "\n",
    "covid_df = download_findthemasks_data(ny_times_county_data_url, ny_times_covid_date, write_out_csv = True)\n",
    "covid_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_covid_ppe_df(covid_df,merged_df): \n",
    "    merged_covid_ppe_df = merged_df.join(\n",
    "        covid_df[['fips','cases','deaths']].set_index('fips'),\n",
    "        on='fips',  how='left', lsuffix='merged', rsuffix='covid_df')\n",
    "    \n",
    "    # fill the NA in counts with 0s\n",
    "    merged_covid_ppe_df['cases'].fillna(0, inplace=True)\n",
    "    merged_covid_ppe_df['deaths'].fillna(0, inplace=True)\n",
    "    \n",
    "    # Create text column for use in mapping\n",
    "    merged_covid_ppe_df['covid_text'] = merged_covid_ppe_df['county'].astype(str) + ', ' + \\\n",
    "        merged_covid_ppe_df['STATE'].astype(str) + '<br><br>'+\\\n",
    "        'Covid19: ' + '<br>'+ \\\n",
    "        'Cases: ' + merged_covid_ppe_df['cases'].astype(int).astype(str) + '<br>'+ \\\n",
    "        'Deaths: ' + merged_covid_ppe_df['deaths'].astype(int).astype(str) + '<br><br>'+ \\\n",
    "        'PPE Requests: ' + merged_covid_ppe_df['PPE_requests'].astype(int).astype(str)\n",
    "        \n",
    "    return merged_covid_ppe_df\n",
    "\n",
    "\n",
    "merged_covid_ppe_df=merge_covid_ppe_df(covid_df,merged_df) \n",
    "merged_covid_ppe_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Merge the counties geojson for all of new york"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counties['features'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "from shapely.geometry import Polygon\n",
    "from shapely.ops import cascaded_union\n",
    "\n",
    "polygon1 = Polygon([(0, 0), (5, 3), (5, 0)])\n",
    "polygon2 = Polygon([(0, 0), (3, 10), (3, 0)])\n",
    "\n",
    "polygons = [polygon1, polygon2]\n",
    "\n",
    "u = cascaded_union(polygons)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping covid cases "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choropleth_mapbox_usa_plot(\n",
    "    counties = counties,\n",
    "    locations = merged_covid_ppe_df.fips,\n",
    "    z = merged_covid_ppe_df.cases,\n",
    "    text = merged_covid_ppe_df.covid_text,\n",
    "    colorscale = [\"#fdfcef\",\"#ffda55\",\"#FFC831\",\"#fc7555\",\"#e96e81\",],\n",
    "    zmin = 0,\n",
    "    zmax=100,\n",
    "    title = ('COVID19 Cases Per County - %s - (Hover for breakdown)' % ny_times_covid_date),\n",
    "    html_filename = ('COVID19_Cases_Per_County_%s.html' % ny_times_covid_date),\n",
    "    colorbar_title = '> COVID19 Cases',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hospital bed visualization by county "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_hospital_data(url, write_out_csv = True):\n",
    "    hospital_df = pd.read_csv(hospital_download_url)\n",
    "    # Start tdqm timer from tqdm.auto\n",
    "    tqdm.pandas()\n",
    "\n",
    "    # Reverse geocoder used to get geocoded fips and county information\n",
    "    # Note: Progress_apply is used for the timer functionality\n",
    "    hospital_df['fips'] = hospital_df.progress_apply(\n",
    "        lambda x: geocoder.fips_code_lookup(x['COUNTY'], x['STATE']), axis=1)\n",
    "    \n",
    "    # clean the BEDS column to make sure all are positive in value, by converting negative beds to 0\n",
    "    hospital_df.sort_values(by=['BEDS'], ascending=False, inplace=True)\n",
    "    hospital_df['BEDS'][hospital_df['BEDS'] < 0] = 0\n",
    "    \n",
    "    # write out this data file to csv\n",
    "    if write_out_csv:\n",
    "        timestr = time.strftime(\"%Y%m%d\")\n",
    "        path = 'hospital_data_processed_' + timestr + '.csv'\n",
    "        mask_df.to_csv (path, index = False, header=True)\n",
    "\n",
    "    return hospital_df\n",
    "\n",
    "\n",
    "hospital_df = download_hospital_data(hospital_download_url, write_out_csv = True)\n",
    "hospital_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_hospital_data(hospital_df, write_out_csv = True):\n",
    "    # Sum the amount of beds per county\n",
    "    hospital_df_counties = hospital_df.groupby(['fips','COUNTY'])['BEDS'].sum().reset_index()\n",
    "\n",
    "    # write out this data file to csv\n",
    "    if write_out_csv:\n",
    "        timestr = time.strftime(\"%Y%m%d\")\n",
    "        path = 'hospital_data_county_data_' + timestr + '.csv'\n",
    "        mask_df.to_csv (path, index = False, header=True)\n",
    "        \n",
    "    return hospital_df_counties\n",
    "    \n",
    "    \n",
    "hospital_df_counties = process_hospital_data(hospital_df, write_out_csv = True)\n",
    "hospital_df_counties.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_covid_ppe_hosp_df(hospital_df_counties,merged_covid_ppe_df): \n",
    "    merged_covid_ppe_hosp_df = merged_covid_ppe_df.join(\n",
    "        hospital_df_counties[['fips','BEDS']].set_index('fips'),\n",
    "        on='fips',  how='left', lsuffix='merged', rsuffix='hospital')\n",
    "    \n",
    "    # fill the NA in counts with 0s\n",
    "    merged_covid_ppe_hosp_df['BEDS'].fillna(0, inplace=True)\n",
    "    \n",
    "    # Create text column for use in mapping\n",
    "    merged_covid_ppe_hosp_df['hosp_text'] = merged_covid_ppe_hosp_df['county'].astype(str) + ', ' + \\\n",
    "        merged_covid_ppe_hosp_df['STATE'].astype(str) + '<br><br>'+\\\n",
    "        'Hospital Beds: ' + merged_covid_ppe_hosp_df['BEDS'].astype(int).astype(str) + '<br>'+ \\\n",
    "        '<br>'+ \\\n",
    "        'Covid19: ' + '<br>'+ \\\n",
    "        'Cases: ' + merged_covid_ppe_hosp_df['cases'].astype(int).astype(str) + '<br>'+ \\\n",
    "        'Deaths: ' + merged_covid_ppe_hosp_df['deaths'].astype(int).astype(str) + '<br><br>'+ \\\n",
    "        'PPE Requests: ' + merged_covid_ppe_hosp_df['PPE_requests'].astype(int).astype(str)\n",
    "        \n",
    "    return merged_covid_ppe_hosp_df\n",
    "\n",
    "\n",
    "merged_covid_ppe_hosp_df=merge_covid_ppe_hosp_df(hospital_df_counties,merged_covid_ppe_df) \n",
    "merged_covid_ppe_hosp_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hospital bed plotting\n",
    "choropleth_mapbox_usa_plot(\n",
    "    counties = counties,\n",
    "    locations = merged_covid_ppe_hosp_df.fips,\n",
    "    z = merged_covid_ppe_hosp_df.BEDS,\n",
    "    text = merged_covid_ppe_hosp_df.hosp_text,\n",
    "    colorscale = [\"#fdfcef\",\"#c7e9b4\",\"#D2FBFF\",\"#36A2B9\",\"#004469\"],\n",
    "    zmin = 0,\n",
    "    zmax=500,\n",
    "    title = ('Hospital beds per county - %s - (Hover for breakdown)' % time.strftime(\"%Y%m%d\")),\n",
    "    html_filename = ('Hospital_beds_per_county_%s.html' % time.strftime(\"%Y%m%d\")),\n",
    "    colorbar_title = '> Hospital Beds'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Covid cases per bed available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to avoid divide by zero problem in lambda\n",
    "def weird_division(n, d):\n",
    "    return n / d if d else 0\n",
    "\n",
    "def calculate_covid_per_bed_available(merged_covid_ppe_hosp_df):\n",
    "    # calculate the covid patients per bed, adding the column that saves this info\n",
    "    merged_covid_ppe_hosp_df['Covid_cases_per_bed'] = merged_covid_ppe_hosp_df.apply(\n",
    "            lambda x: (weird_division(x['cases'], x['BEDS'])), axis=1)\n",
    "    \n",
    "    # sort by highest normalized_covid_patients_per_bed\n",
    "    merged_covid_ppe_hosp_df.sort_values(by='Covid_cases_per_bed', ascending=False, inplace=True)\n",
    "    \n",
    "    # Create text column for use in mapping\n",
    "    merged_covid_ppe_hosp_df['hosp_text'] = merged_covid_ppe_hosp_df['county'].astype(str) + ', ' + \\\n",
    "        merged_covid_ppe_hosp_df['STATE'].astype(str) + '<br><br>'+ \\\n",
    "        'HAZARD RATIO (Cases/Bed): ' + merged_covid_ppe_hosp_df['Covid_cases_per_bed'].astype(float).astype(str) + '<br><br>'+ \\\n",
    "        'Hospital Beds: ' + merged_covid_ppe_hosp_df['BEDS'].astype(int).astype(str) + '<br>'+ \\\n",
    "        '<br>'+ \\\n",
    "        'Covid19: ' + '<br>'+ \\\n",
    "        'Cases: ' + merged_covid_ppe_hosp_df['cases'].astype(int).astype(str) + '<br>'+ \\\n",
    "        'Deaths: ' + merged_covid_ppe_hosp_df['deaths'].astype(int).astype(str) + '<br><br>'+ \\\n",
    "        'PPE Requests: ' + merged_covid_ppe_hosp_df['PPE_requests'].astype(int).astype(str)\n",
    "    \n",
    "    return merged_covid_ppe_hosp_df\n",
    "\n",
    "\n",
    "merged_covid_ppe_hosp_df = calculate_covid_per_bed_available(merged_covid_ppe_hosp_df)\n",
    "merged_covid_ppe_hosp_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map hazard ratio\n",
    "choropleth_mapbox_usa_plot(\n",
    "    counties = counties,\n",
    "    locations = merged_covid_ppe_hosp_df.fips,\n",
    "    z = merged_covid_ppe_hosp_df.Covid_cases_per_bed,\n",
    "    text = merged_covid_ppe_hosp_df.hosp_text,\n",
    "    colorscale = [\"#fdfcef\",\"#ffda55\",\"#FFC831\",\"#fc7555\",\"#e96e81\",],\n",
    "    zmin = 0,\n",
    "    zmax=1,\n",
    "    title = ('Hazard Ratio: Covid19 Cases, Per Bed, Per County - %s - (Hover for breakdown)' % ny_times_covid_date),\n",
    "    html_filename = ('Covid19_cases_per_bed_per_county_%s.html' % time.strftime(\"%Y%m%d\")),\n",
    "    colorbar_title = '> Hazard Ratio (Cases/Bed)'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counties without PPE requests, with highest Covid19 cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_counties_with_covid19_and_no_ppe_request(covid_df, mask_df_counties):\n",
    "    # join the covid patients dataframe with the beds per county dataframe, on the fips index\n",
    "    covid_ppe_df = covid_df.join(\n",
    "        mask_df_counties.set_index('fips'), on='fips',  how='left', lsuffix='_covid', rsuffix='_ppe')\n",
    "    \n",
    "    # fill the NA in normalized_covid_patients_per_bedwith 0s\n",
    "    covid_ppe_df['counts'].fillna(0, inplace=True)\n",
    "    \n",
    "    # sort by highest normalized_covid_patients_per_bed\n",
    "    covid_ppe_df.sort_values(by=['counts','cases'], ascending=(True, False), inplace=True)\n",
    "    \n",
    "    # change name of column 'counts' to 'PPE_requests' \n",
    "    covid_ppe_df.rename(inplace=True,\n",
    "        columns={'counts':'PPE_requests', 'county_covid':'county'})\n",
    "    \n",
    "    ### TODO\n",
    "    # There may be a mismatch of the PPE requests lat/long and those of the hospital data\n",
    "    # since District of Columbia is appearing at the top, and that is unlikely\n",
    "    \n",
    "    return covid_ppe_df\n",
    "\n",
    "\n",
    "covid_ppe_df = find_counties_with_covid19_and_no_ppe_request(covid_df, mask_df_counties)\n",
    "covid_ppe_df[['date','county','state','cases','deaths','PPE_requests']].head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the counties that have no_ppe_requests and covid cases\n",
    "counties_with_no_ppe_requests_and_covid_cases = covid_ppe_df[covid_ppe_df.PPE_requests == 0]\n",
    "\n",
    "# Map covid cases in counties that do not have PPE requests\n",
    "choropleth_mapbox_usa_plot(\n",
    "    counties = counties,\n",
    "    locations = counties_with_no_ppe_requests_and_covid_cases.fips,\n",
    "    z = counties_with_no_ppe_requests_and_covid_cases.cases,\n",
    "    text = counties_with_no_ppe_requests_and_covid_cases.county,\n",
    "    colorscale = \"RdBu_r\",\n",
    "    zmin = 0,\n",
    "    zmax=100,\n",
    "    title = 'Counties that have covid cases and 0 PPE requests'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation of PPE request per county with COVID19 cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select counties that have had at least 1 ppe request\n",
    "counties_with_ppe_requests_and_covid_cases = covid_ppe_df[covid_ppe_df.PPE_requests != 0]\n",
    "\n",
    "# join with the dataframe that has covid cases per hospital bed\n",
    "covid_ppe_df = counties_with_ppe_requests_and_covid_cases.join(\n",
    "    covid_per_bed_df[['county','state','fips','Covid_cases_per_bed','BEDS',]].set_index('fips'),\n",
    "    on='fips',  how='left', lsuffix='', rsuffix='_ppe')\n",
    "\n",
    "# sort by highest normalized_covid_patients_per_bed\n",
    "counties_with_ppe_requests_and_covid_cases.sort_values(by=['PPE_requests','cases'], ascending=False, inplace=True)\n",
    "counties_with_ppe_requests_and_covid_cases[\n",
    "    ['date','county','state','cases','deaths','BEDS','PPE_requests','Covid_cases_per_bed']].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(\n",
    "    counties_with_ppe_requests_and_covid_cases,\n",
    "    x=counties_with_ppe_requests_and_covid_cases.cases, \n",
    "    y=counties_with_ppe_requests_and_covid_cases.PPE_requests,\n",
    "    color='Covid_cases_per_bed',\n",
    "    log_x=True,\n",
    "    #log_y=True,\n",
    "    labels={\n",
    "        'Covid_cases_per_bed':'Covid19 cases per hospital bed',\n",
    "        'x':'Covid19 Cases Per County',\n",
    "        'y':'PPE Requests Per County',\n",
    "        'text':'County'\n",
    "        },\n",
    "    hover_name=counties_with_ppe_requests_and_covid_cases.county,\n",
    "    range_color=(0,1),\n",
    "    range_x=(1,30000)\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    title = \"Correlation of PPE request per county with COVID19 cases\",\n",
    "    #hoverlabel={'text'},\n",
    "    )\n",
    "\n",
    "#fig.update_xaxes(nticks=30)\n",
    "#fig.update_yaxes(nticks=20)\n",
    "    \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://getusppe.github.io/PPE_Requests_Per_County/.embed\" height=\"525\" width=\"100%\"></iframe>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
